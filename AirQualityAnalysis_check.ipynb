{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67f64c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (1.2.3)\n",
      "Requirement already satisfied: mysql-connector-python in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (9.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 25.0 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "955cd7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from data201 import db_connection\n",
    "from mysql.connector import errorcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "544fa8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('Air_pollution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d09bcbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unique ID   District        Date          Measure  Longitude  Latitude  \\\n",
      "0   01BBF6AD     Mumbai  01-12-2010        NO2 (ppb)    72.8777   19.0760   \n",
      "1   00ED349D    Kolkata  01-10-2011     PM10 (µg/m³)    88.3639   22.5726   \n",
      "2   01EA78C9  Bengaluru  01-12-2008     PM10 (µg/m³)    77.5946   12.9716   \n",
      "3   0164FDF7    Chennai  01-08-2014        NO2 (ppb)    80.2707   13.0827   \n",
      "4   0244B8FE    Chennai  01-07-2013        NO2 (ppb)    80.2707   13.0827   \n",
      "..       ...        ...         ...              ...        ...       ...   \n",
      "95  00D2085F     Mumbai  01-04-2000        NO2 (ppb)    72.8777   19.0760   \n",
      "96  00440C22  Bengaluru  01-08-2005  Ozone (O3, ppb)    77.5946   12.9716   \n",
      "97  023B3084    Kolkata  01-03-2019        NO2 (ppb)    88.3639   22.5726   \n",
      "98  00F3A410     Mumbai  01-11-2021  Ozone (O3, ppb)    72.8777   19.0760   \n",
      "99  0099F5ED    Kolkata  01-04-2001  Ozone (O3, ppb)    88.3639   22.5726   \n",
      "\n",
      "   Time Period  Data Value Air Quality  \n",
      "0      Monthly          32    Moderate  \n",
      "1      Monthly         107        Poor  \n",
      "2      Monthly         178   Very Poor  \n",
      "3      Monthly          49    Moderate  \n",
      "4      Monthly           9        Good  \n",
      "..         ...         ...         ...  \n",
      "95     Monthly          11        Good  \n",
      "96     Monthly          53        Good  \n",
      "97     Monthly          35    Moderate  \n",
      "98     Monthly          50        Good  \n",
      "99     Monthly          31        Good  \n",
      "\n",
      "[100 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Transform: Select relevant columns and limit to 100 rows\n",
    "df_100 = df.head(100)\n",
    "print(df_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d509364",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = db_connection(config_file = 'joinforce.ini')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b550a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create District table (One-to-One relationship with Location)\n",
    "    \n",
    "sql = ( \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS district (\n",
    "        district_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        district_name VARCHAR(100) NOT NULL UNIQUE\n",
    "    )\"\"\")\n",
    "\n",
    "cursor.execute(sql);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "598620d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Location table (One-to-One relationship with District)\n",
    "#doesn't work if district_id is used as primary key for multiple tables:https://stackoverflow.com/questions/55631622/can-i-use-one-same-primary-key-in-two-different-tables\n",
    "    \n",
    "cursor.execute('DROP TABLE IF EXISTS location')\n",
    "sql = ( \"\"\"CREATE TABLE location (\n",
    "        location_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        longitude FLOAT,\n",
    "        latitude FLOAT,\n",
    "        district_id INT,\n",
    "        FOREIGN KEY (district_id) REFERENCES district(district_id) ON DELETE CASCADE\n",
    "        )\"\"\")\n",
    "\n",
    "cursor.execute(sql);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "795feb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pollutant table(one-to-many relationship with District))\n",
    "\n",
    "sql = (\"\"\"CREATE TABLE IF NOT EXISTS pollutant (\n",
    "        pollutant_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        measure VARCHAR(50))\"\"\")\n",
    "\n",
    "cursor.execute(sql);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57b2c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AirQuality table (Many-to-Many relationship between AirQuality and Pollutant)\n",
    "\n",
    "sql = (\"\"\"CREATE TABLE IF NOT EXISTS air_quality (\n",
    "        aq_id VARCHAR(70) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci PRIMARY KEY,\n",
    "        district_id INT ,\n",
    "        date DATE NOT NULL,\n",
    "        measure VARCHAR(50) NOT NULL,\n",
    "        data_value FLOAT NOT NULL,\n",
    "        air_quality VARCHAR(70) NOT NULL,\n",
    "        FOREIGN KEY (district_id) REFERENCES district(district_id) ON DELETE CASCADE);\"\"\")\n",
    "\n",
    "cursor.execute(sql);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24192524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create AQPollutant table \n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS aq_pollutant\")\n",
    "\n",
    "sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS aq_pollutant (\n",
    "    aq_id VARCHAR(70) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci,\n",
    "    pollutant_id INT,\n",
    "    PRIMARY KEY (aq_id, pollutant_id),\n",
    "    FOREIGN KEY (aq_id) REFERENCES air_quality(aq_id) ON DELETE CASCADE,\n",
    "    FOREIGN KEY (pollutant_id) REFERENCES pollutant(pollutant_id) ON DELETE CASCADE\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62fb530c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is ['Mumbai', 'Kolkata', 'Bengaluru', 'Chennai', 'Delhi']\n",
      "Districts to Insert: [('Mumbai',), ('Kolkata',), ('Bengaluru',), ('Chennai',), ('Delhi',)]\n",
      "Successfully inserted district: 5\n",
      "MySQL connection is closed.\n"
     ]
    }
   ],
   "source": [
    "# SQL query to insert data in District\n",
    "    \n",
    "try:\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        if 'District' not in df.columns:\n",
    "            raise ValueError(\"Column 'district_name' not found in the DataFrame.\")\n",
    "\n",
    "        # Convert to list of tuples\n",
    "        unique_districts = df_100['District'].dropna().unique().tolist()\n",
    "        print(f\"this is {unique_districts}\")\n",
    "        all_district_name = [(district,) for district in unique_districts]\n",
    "        print(f\"Districts to Insert: {all_district_name}\")\n",
    "        if not all_district_name:\n",
    "            raise ValueError(\" No valid district names found for insertion.\")\n",
    "            \n",
    "        insert_query = \"INSERT INTO district (district_name) VALUES (%s)\"\n",
    "        cursor.executemany(insert_query, all_district_name)\n",
    "        conn.commit()\n",
    "        print(f\"Successfully inserted district: {cursor.rowcount}\")\n",
    "\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"Error while inserting data: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"MySQL connection is closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "169c9cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data to Insert: [(72.8777, 19.076, 1), (88.3639, 22.5726, 2), (77.5946, 12.9716, 3), (80.2707, 13.0827, 4), (80.2707, 13.0827, 4), (77.1025, 28.7041, 5), (88.3639, 22.5726, 2), (77.5946, 12.9716, 3), (77.5946, 12.9716, 3), (88.3639, 22.5726, 2), (72.8777, 19.076, 1), (77.5946, 12.9716, 3), (77.1025, 28.7041, 5), (88.3639, 22.5726, 2), (88.3639, 22.5726, 2), (88.3639, 22.5726, 2), (88.3639, 22.5726, 2), (77.1025, 28.7041, 5), (88.3639, 22.5726, 2), (80.2707, 13.0827, 4), (72.8777, 19.076, 1), (77.5946, 12.9716, 3), (88.3639, 22.5726, 2), (80.2707, 13.0827, 4), (88.3639, 22.5726, 2), (77.5946, 12.9716, 3), (72.8777, 19.076, 1), (72.8777, 19.076, 1), (77.5946, 12.9716, 3), (72.8777, 19.076, 1), (72.8777, 19.076, 1), (77.5946, 12.9716, 3), (77.1025, 28.7041, 5), (88.3639, 22.5726, 2), (77.5946, 12.9716, 3), (77.5946, 12.9716, 3), (80.2707, 13.0827, 4), (77.1025, 28.7041, 5), (72.8777, 19.076, 1), (77.1025, 28.7041, 5), (88.3639, 22.5726, 2), (80.2707, 13.0827, 4), (88.3639, 22.5726, 2), (77.5946, 12.9716, 3), (72.8777, 19.076, 1), (80.2707, 13.0827, 4), (80.2707, 13.0827, 4), (77.1025, 28.7041, 5), (72.8777, 19.076, 1), (77.5946, 12.9716, 3), (77.5946, 12.9716, 3), (88.3639, 22.5726, 2), (77.5946, 12.9716, 3), (77.5946, 12.9716, 3), (80.2707, 13.0827, 4), (77.5946, 12.9716, 3), (80.2707, 13.0827, 4), (77.1025, 28.7041, 5), (72.8777, 19.076, 1), (77.1025, 28.7041, 5), (72.8777, 19.076, 1), (77.1025, 28.7041, 5), (77.5946, 12.9716, 3), (88.3639, 22.5726, 2), (77.5946, 12.9716, 3), (80.2707, 13.0827, 4), (72.8777, 19.076, 1), (77.5946, 12.9716, 3), (72.8777, 19.076, 1), (88.3639, 22.5726, 2), (88.3639, 22.5726, 2), (80.2707, 13.0827, 4), (88.3639, 22.5726, 2), (72.8777, 19.076, 1), (77.1025, 28.7041, 5), (77.1025, 28.7041, 5), (80.2707, 13.0827, 4), (88.3639, 22.5726, 2), (88.3639, 22.5726, 2), (77.1025, 28.7041, 5), (77.5946, 12.9716, 3), (77.1025, 28.7041, 5), (77.1025, 28.7041, 5), (77.5946, 12.9716, 3), (77.1025, 28.7041, 5), (72.8777, 19.076, 1), (72.8777, 19.076, 1), (80.2707, 13.0827, 4), (77.1025, 28.7041, 5), (77.1025, 28.7041, 5), (88.3639, 22.5726, 2), (77.5946, 12.9716, 3), (80.2707, 13.0827, 4), (77.5946, 12.9716, 3), (88.3639, 22.5726, 2), (72.8777, 19.076, 1), (77.5946, 12.9716, 3), (88.3639, 22.5726, 2), (72.8777, 19.076, 1), (88.3639, 22.5726, 2)]\n",
      "Successfully inserted 100 rows.\n",
      "MySQL connection is closed.\n"
     ]
    }
   ],
   "source": [
    "#reconnect to db\n",
    "conn = db_connection(config_file = 'joinforce.ini')\n",
    "\n",
    "# SQL query to insert data in Location\n",
    "\n",
    "try:\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Drop NaN values\n",
    "    df_cleaned = df_100.dropna(subset=['Longitude', 'Latitude', 'District'])\n",
    "\n",
    "    # Fetch district_id for each district_name\n",
    "    district_map = {}\n",
    "    cursor.execute(\"SELECT district_id, district_name FROM district\")\n",
    "    for district_id, district_name in cursor.fetchall():\n",
    "        district_map[district_name] = district_id  # Create a mapping\n",
    "\n",
    "    # Map district_name to district_id\n",
    "    df_cleaned['district_id'] = df_cleaned['District'].map(district_map)\n",
    "\n",
    "    # Remove rows where district_id is NULL (invalid mapping)\n",
    "    df_cleaned = df_cleaned.dropna(subset=['district_id'])\n",
    "\n",
    "    # Convert district_id to int (ensure it's not an object type)\n",
    "    df_cleaned['district_id'] = df_cleaned['district_id'].astype(int)\n",
    "\n",
    "    # Convert DataFrame to list of tuples\n",
    "    data = list(df_cleaned[['Longitude', 'Latitude', 'district_id']].itertuples(index=False, name=None))\n",
    "\n",
    "    print(f\"Data to Insert: {data}\")\n",
    "\n",
    "    if not data:\n",
    "        raise ValueError(\"No valid data found for insertion.\")\n",
    "\n",
    "    # Corrected Insert Query (including district_id)\n",
    "    insert_query = \"INSERT INTO location (longitude, latitude, district_id) VALUES (%s, %s, %s)\"\n",
    "    cursor.executemany(insert_query, data)\n",
    "    conn.commit()\n",
    "\n",
    "    print(f\"Successfully inserted {cursor.rowcount} rows.\")\n",
    "\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"Error while inserting data: {e}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"MySQL connection is closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4a8bf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data to Insert: [('NO2 (ppb)',), ('PM10 (µg/m³)',), ('PM10 (µg/m³)',), ('NO2 (ppb)',), ('NO2 (ppb)',), ('SO2 (ppb)',), ('Ozone (O3, ppb)',), ('NO2 (ppb)',), ('PM2.5 (µg/m³)',), ('PM2.5 (µg/m³)',), ('SO2 (ppb)',), ('PM2.5 (µg/m³)',), ('PM10 (µg/m³)',), ('PM10 (µg/m³)',), ('NO2 (ppb)',), ('PM2.5 (µg/m³)',), ('PM2.5 (µg/m³)',), ('PM10 (µg/m³)',), ('PM10 (µg/m³)',), ('NO2 (ppb)',), ('SO2 (ppb)',), ('NO2 (ppb)',), ('PM2.5 (µg/m³)',), ('PM10 (µg/m³)',), ('PM2.5 (µg/m³)',), ('PM2.5 (µg/m³)',), ('SO2 (ppb)',), ('PM2.5 (µg/m³)',), ('PM10 (µg/m³)',), ('PM2.5 (µg/m³)',), ('PM2.5 (µg/m³)',), ('SO2 (ppb)',), ('Ozone (O3, ppb)',), ('SO2 (ppb)',), ('PM10 (µg/m³)',), ('PM2.5 (µg/m³)',), ('Ozone (O3, ppb)',), ('PM10 (µg/m³)',), ('Ozone (O3, ppb)',), ('PM10 (µg/m³)',), ('PM10 (µg/m³)',), ('PM2.5 (µg/m³)',), ('Ozone (O3, ppb)',), ('PM2.5 (µg/m³)',), ('Ozone (O3, ppb)',), ('PM2.5 (µg/m³)',), ('PM10 (µg/m³)',), ('SO2 (ppb)',), ('Ozone (O3, ppb)',), ('Ozone (O3, ppb)',), ('Ozone (O3, ppb)',), ('PM10 (µg/m³)',), ('NO2 (ppb)',), ('PM2.5 (µg/m³)',), ('PM10 (µg/m³)',), ('PM10 (µg/m³)',), ('NO2 (ppb)',), ('Ozone (O3, ppb)',), ('PM2.5 (µg/m³)',), ('SO2 (ppb)',), ('SO2 (ppb)',), ('NO2 (ppb)',), ('PM10 (µg/m³)',), ('Ozone (O3, ppb)',), ('SO2 (ppb)',), ('NO2 (ppb)',), ('PM10 (µg/m³)',), ('Ozone (O3, ppb)',), ('PM2.5 (µg/m³)',), ('Ozone (O3, ppb)',), ('Ozone (O3, ppb)',), ('SO2 (ppb)',), ('PM2.5 (µg/m³)',), ('NO2 (ppb)',), ('PM2.5 (µg/m³)',), ('PM2.5 (µg/m³)',), ('Ozone (O3, ppb)',), ('PM2.5 (µg/m³)',), ('SO2 (ppb)',), ('SO2 (ppb)',), ('PM10 (µg/m³)',), ('Ozone (O3, ppb)',), ('SO2 (ppb)',), ('Ozone (O3, ppb)',), ('NO2 (ppb)',), ('PM2.5 (µg/m³)',), ('NO2 (ppb)',), ('PM2.5 (µg/m³)',), ('Ozone (O3, ppb)',), ('NO2 (ppb)',), ('PM2.5 (µg/m³)',), ('Ozone (O3, ppb)',), ('SO2 (ppb)',), ('PM10 (µg/m³)',), ('PM2.5 (µg/m³)',), ('NO2 (ppb)',), ('Ozone (O3, ppb)',), ('NO2 (ppb)',), ('Ozone (O3, ppb)',), ('Ozone (O3, ppb)',)]\n",
      "Successfully inserted 100 rows.\n",
      "MySQL connection is closed.\n"
     ]
    }
   ],
   "source": [
    "#reconnect to db\n",
    "conn = db_connection(config_file = 'joinforce.ini')\n",
    "\n",
    "# SQL query to insert data in Pollutant\n",
    "\n",
    "try:\n",
    "    \n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Ensure required columns exist\n",
    "        if 'Longitude' not in df_100.columns or 'Latitude' not in df_100.columns:\n",
    "            raise ValueError(\"Required columns ('Longitude', 'Latitude') not found in the DataFrame.\")\n",
    "            \n",
    "            print(df_100['Measure'].dtype)\n",
    "\n",
    "\n",
    "        # Convert DataFrame to list of tuples \n",
    "        data = [(measure,) for measure in df_100['Measure'].astype(str)]\n",
    "\n",
    "        print(f\"Data to Insert: {data}\")\n",
    "\n",
    "        if not data:\n",
    "            raise ValueError(\"No valid data found for insertion.\")\n",
    "\n",
    "        # Insert data into MySQL\n",
    "        insert_query = \"INSERT INTO pollutant (measure) VALUES (%s)\"\n",
    "        cursor.executemany(insert_query, data)\n",
    "        conn.commit()\n",
    "\n",
    "        print(f\"Successfully inserted {cursor.rowcount} rows.\")\n",
    "\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"Error while inserting data: {e}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"MySQL connection is closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc4146c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of aq_id: 8\n",
      "Unique ID    object\n",
      "dtype: object\n",
      "   Unique ID\n",
      "0   01BBF6AD\n",
      "1   00ED349D\n",
      "2   01EA78C9\n",
      "3   0164FDF7\n",
      "4   0244B8FE\n",
      "..       ...\n",
      "95  00D2085F\n",
      "96  00440C22\n",
      "97  023B3084\n",
      "98  00F3A410\n",
      "99  0099F5ED\n",
      "\n",
      "[100 rows x 1 columns]\n",
      "Data to Insert: [('01BBF6AD', 1, '2010-01-12', 'NO2 (ppb)', 32, 'Moderate'), ('00ED349D', 2, '2011-01-10', 'PM10 (µg/m³)', 107, 'Poor'), ('01EA78C9', 3, '2008-01-12', 'PM10 (µg/m³)', 178, 'Very Poor'), ('0164FDF7', 4, '2014-01-08', 'NO2 (ppb)', 49, 'Moderate'), ('0244B8FE', 4, '2013-01-07', 'NO2 (ppb)', 9, 'Good'), ('01FF75BF', 5, '2018-01-04', 'SO2 (ppb)', 37, 'Moderate'), ('00EF0055', 2, '2011-01-02', 'Ozone (O3, ppb)', 45, 'Good'), ('01B78829', 3, '2007-01-12', 'NO2 (ppb)', 34, 'Moderate'), ('014F4102', 3, '2017-01-05', 'PM2.5 (µg/m³)', 58, 'Moderate'), ('00EC0414', 2, '2022-01-12', 'PM2.5 (µg/m³)', 173, 'Very Poor'), ('0083025A', 1, '2004-01-05', 'SO2 (ppb)', 44, 'Moderate'), ('021B3031', 3, '2009-01-08', 'PM2.5 (µg/m³)', 65, 'Moderate'), ('005503F2', 5, '2020-01-07', 'PM10 (µg/m³)', 51, 'Moderate'), ('01146F20', 2, '2006-01-04', 'PM10 (µg/m³)', 51, 'Moderate'), ('012D24EC', 2, '2012-01-01', 'NO2 (ppb)', 46, 'Moderate'), ('007B4B38', 2, '2001-01-12', 'PM2.5 (µg/m³)', 126, 'Poor'), ('01261250', 2, '2022-01-11', 'PM2.5 (µg/m³)', 110, 'Poor'), ('00DA092A', 5, '2014-01-01', 'PM10 (µg/m³)', 91, 'Moderate'), ('00F7CBA3', 2, '2002-01-03', 'PM10 (µg/m³)', 162, 'Very Poor'), ('023AB271', 4, '2022-01-04', 'NO2 (ppb)', 25, 'Good'), ('00E10510', 1, '2002-01-10', 'SO2 (ppb)', 23, 'Good'), ('00DBDE76', 3, '2005-01-10', 'NO2 (ppb)', 26, 'Good'), ('010050CE', 2, '2021-01-03', 'PM2.5 (µg/m³)', 186, 'Very Poor'), ('01546AF2', 4, '2022-01-12', 'PM10 (µg/m³)', 127, 'Poor'), ('0189481F', 2, '2013-01-02', 'PM2.5 (µg/m³)', 57, 'Moderate'), ('0158BA6D', 3, '2006-01-01', 'PM2.5 (µg/m³)', 143, 'Poor'), ('010D1BCD', 1, '2020-01-11', 'SO2 (ppb)', 50, 'Moderate'), ('026ABD08', 1, '2014-01-02', 'PM2.5 (µg/m³)', 138, 'Poor'), ('00AD10C1', 3, '2014-01-02', 'PM10 (µg/m³)', 85, 'Moderate'), ('02842703', 1, '2007-01-08', 'PM2.5 (µg/m³)', 170, 'Very Poor'), ('017914E7', 1, '2007-01-07', 'PM2.5 (µg/m³)', 149, 'Poor'), ('00604AF6', 3, '2001-01-11', 'SO2 (ppb)', 37, 'Moderate'), ('01C7481B', 5, '2020-01-12', 'Ozone (O3, ppb)', 38, 'Good'), ('01EFA687', 2, '2013-01-05', 'SO2 (ppb)', 24, 'Good'), ('00B57E47', 3, '2012-01-11', 'PM10 (µg/m³)', 115, 'Poor'), ('00CEDCDB', 3, '2021-01-06', 'PM2.5 (µg/m³)', 102, 'Poor'), ('0130AFCE', 4, '2007-01-12', 'Ozone (O3, ppb)', 20, 'Good'), ('019F46CD', 5, '2011-01-02', 'PM10 (µg/m³)', 133, 'Poor'), ('021EEB37', 1, '2011-01-12', 'Ozone (O3, ppb)', 65, 'Moderate'), ('01701B02', 5, '2018-01-09', 'PM10 (µg/m³)', 50, 'Moderate'), ('00017E19', 2, '2019-01-09', 'PM10 (µg/m³)', 156, 'Very Poor'), ('01FB8D9E', 4, '2017-01-06', 'PM2.5 (µg/m³)', 176, 'Very Poor'), ('003A7416', 2, '2016-01-01', 'Ozone (O3, ppb)', 21, 'Good'), ('00C72814', 3, '2005-01-11', 'PM2.5 (µg/m³)', 139, 'Poor'), ('01E3D28A', 1, '2004-01-09', 'Ozone (O3, ppb)', 34, 'Good'), ('017970AC', 4, '2022-01-07', 'PM2.5 (µg/m³)', 126, 'Poor'), ('003B7FE0', 4, '2016-01-03', 'PM10 (µg/m³)', 61, 'Moderate'), ('022CCB62', 5, '2015-01-08', 'SO2 (ppb)', 21, 'Good'), ('00142C5A', 1, '2015-01-06', 'Ozone (O3, ppb)', 46, 'Good'), ('003D5558', 3, '2016-01-01', 'Ozone (O3, ppb)', 47, 'Good'), ('017564DB', 3, '2017-01-08', 'Ozone (O3, ppb)', 48, 'Good'), ('0064EB66', 2, '2020-01-12', 'PM10 (µg/m³)', 74, 'Moderate'), ('018B367F', 3, '2012-01-08', 'NO2 (ppb)', 37, 'Moderate'), ('00AFEE76', 3, '2006-01-03', 'PM2.5 (µg/m³)', 140, 'Poor'), ('0160F0C7', 4, '2010-01-12', 'PM10 (µg/m³)', 131, 'Poor'), ('01A5895A', 3, '2006-01-06', 'PM10 (µg/m³)', 115, 'Poor'), ('007481B0', 4, '2006-01-03', 'NO2 (ppb)', 15, 'Good'), ('00A7A002', 5, '2021-01-12', 'Ozone (O3, ppb)', 24, 'Good'), ('01E393BB', 1, '2022-01-01', 'PM2.5 (µg/m³)', 107, 'Poor'), ('00794DF7', 5, '2005-01-12', 'SO2 (ppb)', 9, 'Good'), ('0157C443', 1, '2001-01-07', 'SO2 (ppb)', 50, 'Moderate'), ('01A8391C', 5, '2010-01-06', 'NO2 (ppb)', 22, 'Good'), ('004940C3', 3, '2015-01-04', 'PM10 (µg/m³)', 158, 'Very Poor'), ('003EE43D', 2, '2011-01-05', 'Ozone (O3, ppb)', 82, 'Moderate'), ('006C13DA', 3, '2002-01-08', 'SO2 (ppb)', 39, 'Moderate'), ('02135A16', 4, '2010-01-01', 'NO2 (ppb)', 37, 'Moderate'), ('0111F5A3', 1, '2001-01-04', 'PM10 (µg/m³)', 126, 'Poor'), ('01B3B0A9', 3, '2002-01-04', 'Ozone (O3, ppb)', 42, 'Good'), ('014FBB0A', 1, '2007-01-04', 'PM2.5 (µg/m³)', 71, 'Moderate'), ('00BD5C22', 2, '2000-01-10', 'Ozone (O3, ppb)', 98, 'Moderate'), ('014E0D7F', 2, '2000-01-03', 'Ozone (O3, ppb)', 27, 'Good'), ('013102B1', 4, '2013-01-01', 'SO2 (ppb)', 25, 'Good'), ('021535A4', 2, '2014-01-09', 'PM2.5 (µg/m³)', 77, 'Moderate'), ('00B51973', 1, '2023-01-06', 'NO2 (ppb)', 23, 'Good'), ('0223EFF1', 5, '2007-01-03', 'PM2.5 (µg/m³)', 145, 'Poor'), ('028E3A71', 5, '2002-01-05', 'PM2.5 (µg/m³)', 130, 'Poor'), ('00275230', 4, '2018-01-11', 'Ozone (O3, ppb)', 34, 'Good'), ('01723D0D', 2, '2015-01-01', 'PM2.5 (µg/m³)', 122, 'Poor'), ('026C4C64', 2, '2006-01-08', 'SO2 (ppb)', 21, 'Good'), ('0217C554', 5, '2011-01-10', 'SO2 (ppb)', 41, 'Moderate'), ('014BF43E', 3, '2012-01-12', 'PM10 (µg/m³)', 194, 'Very Poor'), ('0059F9C2', 5, '2012-01-05', 'Ozone (O3, ppb)', 83, 'Moderate'), ('00A908EF', 5, '2021-01-09', 'SO2 (ppb)', 48, 'Moderate'), ('01008643', 3, '2010-01-12', 'Ozone (O3, ppb)', 45, 'Good'), ('0132C22B', 5, '2021-01-08', 'NO2 (ppb)', 10, 'Good'), ('012E6C9F', 1, '2003-01-02', 'PM2.5 (µg/m³)', 152, 'Very Poor'), ('027C588B', 1, '2003-01-01', 'NO2 (ppb)', 37, 'Moderate'), ('00DCED15', 4, '2023-01-12', 'PM2.5 (µg/m³)', 61, 'Moderate'), ('00E3D44F', 5, '2007-01-06', 'Ozone (O3, ppb)', 49, 'Good'), ('008D3569', 5, '2019-01-11', 'NO2 (ppb)', 34, 'Moderate'), ('02412344', 2, '2011-01-01', 'PM2.5 (µg/m³)', 198, 'Very Poor'), ('02056DF1', 3, '2003-01-07', 'Ozone (O3, ppb)', 83, 'Moderate'), ('00836E56', 4, '2002-01-09', 'SO2 (ppb)', 20, 'Good'), ('02899A4F', 3, '2008-01-01', 'PM10 (µg/m³)', 77, 'Moderate'), ('012B2DA3', 2, '2012-01-12', 'PM2.5 (µg/m³)', 101, 'Poor'), ('00D2085F', 1, '2000-01-04', 'NO2 (ppb)', 11, 'Good'), ('00440C22', 3, '2005-01-08', 'Ozone (O3, ppb)', 53, 'Good'), ('023B3084', 2, '2019-01-03', 'NO2 (ppb)', 35, 'Moderate'), ('00F3A410', 1, '2021-01-11', 'Ozone (O3, ppb)', 50, 'Good'), ('0099F5ED', 2, '2001-01-04', 'Ozone (O3, ppb)', 31, 'Good')]\n",
      "Successfully inserted 100 rows.\n",
      "MySQL connection is closed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-c2695672c588>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_100['Date'] = pd.to_datetime(df_100['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n"
     ]
    }
   ],
   "source": [
    "#reconnect to db\n",
    "conn = db_connection(config_file = 'joinforce.ini')\n",
    "\n",
    "# SQL query to insert data in Air Quality\n",
    "try:\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Ensure required columns exist\n",
    "        required_columns = {'Unique ID','Measure', 'Date', 'Data Value', 'Air Quality', 'District'}\n",
    "        if not required_columns.issubset(df_100.columns):\n",
    "            raise ValueError(f\"Required columns {required_columns} not found in the DataFrame.\")\n",
    "\n",
    "        # Convert 'Date' column to MySQL format (YYYY-MM-DD)\n",
    "        df_100['Date'] = pd.to_datetime(df_100['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        #check for \"\" string before dropping\n",
    "        df_100['Unique ID'].replace(\"\", None, inplace=True)\n",
    "        \n",
    "        # Drop NaN values\n",
    "        df_cleaned = df_100.dropna(subset=['Unique ID','Date', 'Measure', 'Data Value', 'Air Quality', 'District'])\n",
    "\n",
    "        #check aq_id\n",
    "        print(\"Max length of aq_id:\", df_cleaned['Unique ID'].astype(str).str.len().max())\n",
    "        df_cleaned['Unique ID'] = df_cleaned['Unique ID'].astype(str).str.strip()\n",
    "        print(df_cleaned[['Unique ID']].dtypes)\n",
    "\n",
    "        df_cleaned['Unique ID'] = df_cleaned['Unique ID'].apply(lambda x: x.encode('utf-8').decode('utf-8'))  # Normalize encoding\n",
    "        df_cleaned['Unique ID'] = df_cleaned['Unique ID'].apply(lambda x: re.sub(r'[^\\x20-\\x7E]', '', x))  # Remove non-ASCII chars\n",
    "        print(df_cleaned[['Unique ID']])\n",
    "              \n",
    "        invalid_chars = df_cleaned['Unique ID'].apply(lambda x: any(ord(c) < 32 or ord(c) > 126 for c in x))\n",
    "        if invalid_chars.any():\n",
    "            print(\"Warning: Some 'Unique ID' values contain hidden special characters!\")\n",
    "            print(df_cleaned.loc[invalid_chars, 'Unique ID'])\n",
    "\n",
    "        \n",
    "        # Fetch  for each district_name\n",
    "        district_map = {}\n",
    "        cursor.execute(\"SELECT district_id, district_name FROM district\")\n",
    "        for district_id, district_name in cursor.fetchall():\n",
    "            district_map[district_name] = district_id  # Create a mapping\n",
    "\n",
    "        # Map district_name to district_id\n",
    "        df_cleaned['district_id'] = df_cleaned['District'].map(district_map)\n",
    "\n",
    "        # Remove rows where district_id is still NULL (invalid mapping)\n",
    "        df_cleaned = df_cleaned.dropna(subset=['district_id'])\n",
    "\n",
    "        # Convert DataFrame to list of tuples\n",
    "        data = list(df_cleaned[['Unique ID','district_id', 'Date', 'Measure', 'Data Value', 'Air Quality']].itertuples(index=False, name=None))\n",
    "\n",
    "        print(f\"Data to Insert: {data}\")\n",
    "\n",
    "        if not data:\n",
    "            raise ValueError(\"No valid data found for insertion.\")\n",
    "\n",
    "        # Corrected Insert Query (including district_id)\n",
    "        insert_query = \"INSERT INTO air_quality (aq_id, district_id, date, measure, data_value, air_quality) VALUES (CAST(%s AS CHAR), %s, %s, %s, %s, %s)\"\n",
    "        cursor.executemany(insert_query, data)\n",
    "        conn.commit()\n",
    "\n",
    "        print(f\"Successfully inserted {cursor.rowcount} rows.\")\n",
    "\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"Error while inserting data: {e}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"MySQL connection is closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9703288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully inserted 100 rows.\n",
      "MySQL connection is closed.\n"
     ]
    }
   ],
   "source": [
    "#reconnect to db\n",
    "conn = db_connection(config_file = 'joinforce.ini')\n",
    "\n",
    "# SQL query to insert data in Aq Pollutant\n",
    "try:\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Fetch mapping for aq_id (from air_quality table) - aq_id is a string!\n",
    "        aq_map = {}\n",
    "        cursor.execute(\"SELECT aq_id FROM air_quality\")\n",
    "        for (aq_id,) in cursor.fetchall(): \n",
    "            aq_map[aq_id] = aq_id  # Store as string\n",
    "\n",
    "        # Fetch mapping for pollutant_id (from pollutant table)\n",
    "        pollutant_map = {}\n",
    "        cursor.execute(\"SELECT pollutant_id, measure FROM pollutant\")  \n",
    "        for pollutant_id, measure in cursor.fetchall(): \n",
    "            pollutant_map[measure] = pollutant_id  # Store as integer\n",
    "\n",
    "        \n",
    "        # Ensure required columns exist\n",
    "        required_columns = {'Unique ID', 'Measure'}\n",
    "        if not required_columns.issubset(df_100.columns):\n",
    "            raise ValueError(f\"Required columns {required_columns} not found in the DataFrame.\")\n",
    "\n",
    "\n",
    "        # Create a cleaned dataframe copy\n",
    "        df_cleaned = df_100.copy()\n",
    "\n",
    "        # Map AQ IDs (keep them as strings)\n",
    "        df_cleaned['aq_id'] = df_cleaned['Unique ID'].map(aq_map)\n",
    "      \n",
    "\n",
    "        # Ensure 'Measure' column exists before mapping to pollutant_id\n",
    "        if 'Measure' in df_cleaned.columns:\n",
    "            df_cleaned['pollutant_id'] = df_cleaned['Measure'].map(pollutant_map)\n",
    "        else:\n",
    "            raise ValueError(\"'Measure' column missing in DataFrame\")\n",
    "\n",
    "\n",
    "        # Handle NaN values in pollutant_id\n",
    "        df_cleaned = df_cleaned.dropna(subset=['aq_id', 'pollutant_id'])\n",
    "        \n",
    "        # Convert pollutant_id to integer (aq_id remains a string)\n",
    "        df_cleaned['pollutant_id'] = df_cleaned['pollutant_id'].astype(int)\n",
    "\n",
    "        # Convert DataFrame to list of tuples\n",
    "        data = list(df_cleaned[['aq_id', 'pollutant_id']].itertuples(index=False, name=None))\n",
    "\n",
    "\n",
    "        if not data:\n",
    "            raise ValueError(\"No valid data found for insertion.\")\n",
    "\n",
    "        # Insert Query (aq_id remains string)\n",
    "        insert_query = \"INSERT INTO aq_pollutant (aq_id, pollutant_id) VALUES (%s, %s)\"\n",
    "        cursor.executemany(insert_query, data)\n",
    "        conn.commit()\n",
    "\n",
    "        print(f\"Successfully inserted {cursor.rowcount} rows.\")\n",
    "\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"Error while inserting data: {e}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"MySQL connection is closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f47edf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       aq_id  district_id        date          measure  data_value air_quality\n",
      "0   00017E19            2  2019-01-09     PM10 (µg/m³)       156.0   Very Poor\n",
      "1   00142C5A            1  2015-01-06  Ozone (O3, ppb)        46.0        Good\n",
      "2   00275230            4  2018-01-11  Ozone (O3, ppb)        34.0        Good\n",
      "3   003A7416            2  2016-01-01  Ozone (O3, ppb)        21.0        Good\n",
      "4   003B7FE0            4  2016-01-03     PM10 (µg/m³)        61.0    Moderate\n",
      "5   003D5558            3  2016-01-01  Ozone (O3, ppb)        47.0        Good\n",
      "6   003EE43D            2  2011-01-05  Ozone (O3, ppb)        82.0    Moderate\n",
      "7   00440C22            3  2005-01-08  Ozone (O3, ppb)        53.0        Good\n",
      "8   004940C3            3  2015-01-04     PM10 (µg/m³)       158.0   Very Poor\n",
      "9   005503F2            5  2020-01-07     PM10 (µg/m³)        51.0    Moderate\n",
      "10  0059F9C2            5  2012-01-05  Ozone (O3, ppb)        83.0    Moderate\n",
      "11  00604AF6            3  2001-01-11        SO2 (ppb)        37.0    Moderate\n",
      "12  0064EB66            2  2020-01-12     PM10 (µg/m³)        74.0    Moderate\n",
      "13  006C13DA            3  2002-01-08        SO2 (ppb)        39.0    Moderate\n",
      "14  007481B0            4  2006-01-03        NO2 (ppb)        15.0        Good\n",
      "15  00794DF7            5  2005-01-12        SO2 (ppb)         9.0        Good\n",
      "16  007B4B38            2  2001-01-12    PM2.5 (µg/m³)       126.0        Poor\n",
      "17  0083025A            1  2004-01-05        SO2 (ppb)        44.0    Moderate\n",
      "18  00836E56            4  2002-01-09        SO2 (ppb)        20.0        Good\n",
      "19  008D3569            5  2019-01-11        NO2 (ppb)        34.0    Moderate\n",
      "20  0099F5ED            2  2001-01-04  Ozone (O3, ppb)        31.0        Good\n",
      "21  00A7A002            5  2021-01-12  Ozone (O3, ppb)        24.0        Good\n",
      "22  00A908EF            5  2021-01-09        SO2 (ppb)        48.0    Moderate\n",
      "23  00AD10C1            3  2014-01-02     PM10 (µg/m³)        85.0    Moderate\n",
      "24  00AFEE76            3  2006-01-03    PM2.5 (µg/m³)       140.0        Poor\n",
      "MySQL connection is closed.\n"
     ]
    }
   ],
   "source": [
    "#reconnect to db\n",
    "conn = db_connection(config_file = 'joinforce.ini')\n",
    "\n",
    "#  Query to fetch first 25 rows\n",
    "try:\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        query = \"SELECT * FROM air_quality LIMIT 25;\"\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        # Get column names from cursor description\n",
    "        column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    " \n",
    "        df_air_quality = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "        print(df_air_quality)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error while executing queries: {e}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"MySQL connection is closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e67a0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " District & Location Results:\n",
      "   district_id district_name  longitude  latitude\n",
      "0            1        Mumbai    72.8777   19.0760\n",
      "1            2       Kolkata    88.3639   22.5726\n",
      "2            3     Bengaluru    77.5946   12.9716\n",
      "3            4       Chennai    80.2707   13.0827\n",
      "4            5       Chennai    80.2707   13.0827\n",
      "5            6         Delhi    77.1025   28.7041\n",
      "6            7       Kolkata    88.3639   22.5726\n",
      "7            8     Bengaluru    77.5946   12.9716\n",
      "8            9     Bengaluru    77.5946   12.9716\n",
      "9           10       Kolkata    88.3639   22.5726\n",
      "\n",
      " Air Quality Per District Results:\n",
      "   district_id district_name        date          measure  data_value  \\\n",
      "0         1690         Delhi  2021-01-12  Ozone (O3, ppb)        24.0   \n",
      "1         1690         Delhi  2021-01-09        SO2 (ppb)        48.0   \n",
      "2         1690         Delhi  2021-01-08        NO2 (ppb)        10.0   \n",
      "3         1690         Delhi  2020-01-12  Ozone (O3, ppb)        38.0   \n",
      "4         1690         Delhi  2020-01-07     PM10 (µg/m³)        51.0   \n",
      "5         1690         Delhi  2019-01-11        NO2 (ppb)        34.0   \n",
      "6         1690         Delhi  2018-01-09     PM10 (µg/m³)        50.0   \n",
      "7         1690         Delhi  2018-01-04        SO2 (ppb)        37.0   \n",
      "8         1690         Delhi  2015-01-08        SO2 (ppb)        21.0   \n",
      "9         1690         Delhi  2014-01-01     PM10 (µg/m³)        91.0   \n",
      "\n",
      "  air_quality  \n",
      "0        Good  \n",
      "1    Moderate  \n",
      "2        Good  \n",
      "3        Good  \n",
      "4    Moderate  \n",
      "5    Moderate  \n",
      "6    Moderate  \n",
      "7    Moderate  \n",
      "8        Good  \n",
      "9    Moderate  \n",
      "\n",
      " District, Location & Air Quality Results:\n",
      "Empty DataFrame\n",
      "Columns: [district_name, longitude, latitude, date, measure, data_value, air_quality]\n",
      "Index: []\n",
      "\n",
      " Average Air Quality Per District Results:\n",
      "  district_name          measure   avg_value\n",
      "0     Bengaluru        NO2 (ppb)   32.333333\n",
      "1     Bengaluru  Ozone (O3, ppb)   53.000000\n",
      "2     Bengaluru     PM10 (µg/m³)  131.714286\n",
      "3     Bengaluru    PM2.5 (µg/m³)  107.833333\n",
      "4     Bengaluru        SO2 (ppb)   38.000000\n",
      "5       Chennai        NO2 (ppb)   27.000000\n",
      "6       Chennai  Ozone (O3, ppb)   27.000000\n",
      "7       Chennai     PM10 (µg/m³)  106.333333\n",
      "8       Chennai    PM2.5 (µg/m³)  121.000000\n",
      "9       Chennai        SO2 (ppb)   22.500000\n",
      "\n",
      " Worst Air Quality District Results:\n",
      "  district_name       measure  data_value air_quality\n",
      "0       Kolkata  PM10 (µg/m³)       156.0   Very Poor\n",
      "MySQL connection is closed.\n"
     ]
    }
   ],
   "source": [
    "#reconnect to db\n",
    "conn = db_connection(config_file = 'joinforce.ini')\n",
    "\n",
    "# 5 queries that i was already experimenting with\n",
    "queries = {\n",
    "    \"District & Location\": \"\"\"\n",
    "        SELECT d.district_id, d.district_name, l.longitude, l.latitude \n",
    "        FROM joinforce_db.district d \n",
    "        JOIN joinforce_db.location l ON d.district_id = l.location_id LIMIT 0, 100;\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Air Quality Per District\": \"\"\"\n",
    "        SELECT d.district_id, d.district_name, a.date, a.measure, a.data_value, a.air_quality\n",
    "        FROM joinforce_db.district d\n",
    "        JOIN joinforce_db.air_quality a ON d.district_id = a.district_id\n",
    "        ORDER BY d.district_id, a.date DESC;\n",
    "    \"\"\",\n",
    "\n",
    "    \"District, Location & Air Quality\": \"\"\"\n",
    "        SELECT d.district_name AS district_name, l.longitude, l.latitude, a.date, a.measure, a.data_value, a.air_quality\n",
    "        FROM joinforce_db.air_quality a\n",
    "        JOIN joinforce_db.district d ON a.district_id = d.district_id\n",
    "        JOIN joinforce_db.location l ON d.district_id = l.location_id \n",
    "        ORDER BY a.date DESC;\n",
    "    \"\"\",\n",
    "\n",
    "    \"Average Air Quality Per District\": \"\"\"\n",
    "        SELECT d.district_name AS district_name, a.measure, AVG(a.data_value) AS avg_value\n",
    "        FROM joinforce_db.air_quality a\n",
    "        JOIN joinforce_db.district d ON a.district_id = d.district_id\n",
    "        GROUP BY d.district_name, a.measure\n",
    "        ORDER BY d.district_name;\n",
    "    \"\"\",\n",
    "\n",
    "    \"Worst Air Quality District\": \"\"\"\n",
    "        SELECT d.district_name AS district_name, a.measure, a.data_value, a.air_quality\n",
    "        FROM joinforce_db.air_quality a\n",
    "        JOIN joinforce_db.district d ON a.district_id = d.district_id\n",
    "        ORDER BY FIELD(a.air_quality, 'Unhealthy', 'Moderate', 'Good') ASC\n",
    "        LIMIT 1;\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        for query_name, sql_query in queries.items():\n",
    "            cursor.execute(sql_query)\n",
    "            rows = cursor.fetchall()\n",
    "\n",
    "            # Get column names from cursor description\n",
    "            column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "            # Create DataFrame\n",
    "            df_result = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "            # Display DataFrame\n",
    "            print(f\"\\n {query_name} Results:\")\n",
    "            print(df_result.head(10))  # Show first 10 rows\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error while executing queries: {e}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"MySQL connection is closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
